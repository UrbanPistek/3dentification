{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the train df: (595038, 1855)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zone</th>\n",
       "      <th>session_id</th>\n",
       "      <th>tag_id</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>...</th>\n",
       "      <th>1841</th>\n",
       "      <th>1842</th>\n",
       "      <th>1843</th>\n",
       "      <th>1844</th>\n",
       "      <th>1845</th>\n",
       "      <th>1846</th>\n",
       "      <th>1847</th>\n",
       "      <th>1848</th>\n",
       "      <th>1849</th>\n",
       "      <th>1850</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Floor 1</td>\n",
       "      <td>216441698810</td>\n",
       "      <td>ad24cd</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.391508</td>\n",
       "      <td>-0.322429</td>\n",
       "      <td>-0.335741</td>\n",
       "      <td>-0.39144</td>\n",
       "      <td>-0.424744</td>\n",
       "      <td>-0.442341</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.265351</td>\n",
       "      <td>-0.264938</td>\n",
       "      <td>-0.332012</td>\n",
       "      <td>-0.323045</td>\n",
       "      <td>-0.285949</td>\n",
       "      <td>-0.280206</td>\n",
       "      <td>-0.310537</td>\n",
       "      <td>-0.255797</td>\n",
       "      <td>-0.310412</td>\n",
       "      <td>-0.290698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Floor 1</td>\n",
       "      <td>216441698810</td>\n",
       "      <td>ad24cd</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.391508</td>\n",
       "      <td>-0.322429</td>\n",
       "      <td>-0.335741</td>\n",
       "      <td>-0.39144</td>\n",
       "      <td>-0.424744</td>\n",
       "      <td>-0.442341</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.265351</td>\n",
       "      <td>-0.264938</td>\n",
       "      <td>-0.332012</td>\n",
       "      <td>-0.323045</td>\n",
       "      <td>-0.285949</td>\n",
       "      <td>-0.280206</td>\n",
       "      <td>-0.310537</td>\n",
       "      <td>-0.255797</td>\n",
       "      <td>-0.310412</td>\n",
       "      <td>-0.290698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Floor 1</td>\n",
       "      <td>216441698810</td>\n",
       "      <td>ad24cd</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.391508</td>\n",
       "      <td>-0.322429</td>\n",
       "      <td>-0.335741</td>\n",
       "      <td>-0.39144</td>\n",
       "      <td>-0.424744</td>\n",
       "      <td>-0.442341</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.265351</td>\n",
       "      <td>-0.264938</td>\n",
       "      <td>-0.332012</td>\n",
       "      <td>-0.323045</td>\n",
       "      <td>-0.285949</td>\n",
       "      <td>-0.280206</td>\n",
       "      <td>-0.310537</td>\n",
       "      <td>-0.255797</td>\n",
       "      <td>-0.310412</td>\n",
       "      <td>-0.290698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Floor 1</td>\n",
       "      <td>216441698810</td>\n",
       "      <td>ad24cd</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.391508</td>\n",
       "      <td>-0.322429</td>\n",
       "      <td>-0.335741</td>\n",
       "      <td>-0.39144</td>\n",
       "      <td>-0.424744</td>\n",
       "      <td>-0.442341</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.265351</td>\n",
       "      <td>-0.264938</td>\n",
       "      <td>-0.332012</td>\n",
       "      <td>-0.323045</td>\n",
       "      <td>-0.285949</td>\n",
       "      <td>-0.280206</td>\n",
       "      <td>-0.310537</td>\n",
       "      <td>-0.255797</td>\n",
       "      <td>-0.310412</td>\n",
       "      <td>-0.290698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Floor 1</td>\n",
       "      <td>216441698810</td>\n",
       "      <td>ad24cd</td>\n",
       "      <td>21</td>\n",
       "      <td>-0.391508</td>\n",
       "      <td>-0.322429</td>\n",
       "      <td>-0.335741</td>\n",
       "      <td>-0.39144</td>\n",
       "      <td>-0.424744</td>\n",
       "      <td>-0.442341</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.265351</td>\n",
       "      <td>-0.264938</td>\n",
       "      <td>-0.332012</td>\n",
       "      <td>-0.323045</td>\n",
       "      <td>-0.285949</td>\n",
       "      <td>-0.280206</td>\n",
       "      <td>-0.310537</td>\n",
       "      <td>-0.255797</td>\n",
       "      <td>-0.310412</td>\n",
       "      <td>-0.290698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1855 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      zone    session_id  tag_id  Unnamed: 3         0         1         2  \\\n",
       "0  Floor 1  216441698810  ad24cd          17 -0.391508 -0.322429 -0.335741   \n",
       "1  Floor 1  216441698810  ad24cd          18 -0.391508 -0.322429 -0.335741   \n",
       "2  Floor 1  216441698810  ad24cd          19 -0.391508 -0.322429 -0.335741   \n",
       "3  Floor 1  216441698810  ad24cd          20 -0.391508 -0.322429 -0.335741   \n",
       "4  Floor 1  216441698810  ad24cd          21 -0.391508 -0.322429 -0.335741   \n",
       "\n",
       "         3         4         5  ...      1841      1842      1843      1844  \\\n",
       "0 -0.39144 -0.424744 -0.442341  ... -0.265351 -0.264938 -0.332012 -0.323045   \n",
       "1 -0.39144 -0.424744 -0.442341  ... -0.265351 -0.264938 -0.332012 -0.323045   \n",
       "2 -0.39144 -0.424744 -0.442341  ... -0.265351 -0.264938 -0.332012 -0.323045   \n",
       "3 -0.39144 -0.424744 -0.442341  ... -0.265351 -0.264938 -0.332012 -0.323045   \n",
       "4 -0.39144 -0.424744 -0.442341  ... -0.265351 -0.264938 -0.332012 -0.323045   \n",
       "\n",
       "       1845      1846      1847      1848      1849      1850  \n",
       "0 -0.285949 -0.280206 -0.310537 -0.255797 -0.310412 -0.290698  \n",
       "1 -0.285949 -0.280206 -0.310537 -0.255797 -0.310412 -0.290698  \n",
       "2 -0.285949 -0.280206 -0.310537 -0.255797 -0.310412 -0.290698  \n",
       "3 -0.285949 -0.280206 -0.310537 -0.255797 -0.310412 -0.290698  \n",
       "4 -0.285949 -0.280206 -0.310537 -0.255797 -0.310412 -0.290698  \n",
       "\n",
       "[5 rows x 1855 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('saved_train_df_idx.csv')\n",
    "print(f\"Shape of the train df: {train_df.shape}\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the validation matrix: (290184, 1855)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zone</th>\n",
       "      <th>session_id</th>\n",
       "      <th>tag_id</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>...</th>\n",
       "      <th>1841</th>\n",
       "      <th>1842</th>\n",
       "      <th>1843</th>\n",
       "      <th>1844</th>\n",
       "      <th>1845</th>\n",
       "      <th>1846</th>\n",
       "      <th>1847</th>\n",
       "      <th>1848</th>\n",
       "      <th>1849</th>\n",
       "      <th>1850</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Floor 1</td>\n",
       "      <td>216441698810</td>\n",
       "      <td>ad24cd</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.391508</td>\n",
       "      <td>-0.322429</td>\n",
       "      <td>-0.335741</td>\n",
       "      <td>-0.39144</td>\n",
       "      <td>-0.424744</td>\n",
       "      <td>-0.442341</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.265351</td>\n",
       "      <td>-0.264938</td>\n",
       "      <td>-0.332012</td>\n",
       "      <td>-0.323045</td>\n",
       "      <td>-0.285949</td>\n",
       "      <td>-0.280206</td>\n",
       "      <td>-0.310537</td>\n",
       "      <td>-0.255797</td>\n",
       "      <td>-0.310412</td>\n",
       "      <td>-0.290698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Floor 1</td>\n",
       "      <td>216441698810</td>\n",
       "      <td>ad24cd</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.391508</td>\n",
       "      <td>-0.322429</td>\n",
       "      <td>-0.335741</td>\n",
       "      <td>-0.39144</td>\n",
       "      <td>-0.424744</td>\n",
       "      <td>-0.442341</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.265351</td>\n",
       "      <td>-0.264938</td>\n",
       "      <td>-0.332012</td>\n",
       "      <td>-0.323045</td>\n",
       "      <td>-0.285949</td>\n",
       "      <td>-0.280206</td>\n",
       "      <td>-0.310537</td>\n",
       "      <td>-0.255797</td>\n",
       "      <td>-0.310412</td>\n",
       "      <td>-0.290698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Floor 1</td>\n",
       "      <td>216441698810</td>\n",
       "      <td>ad24cd</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.391508</td>\n",
       "      <td>-0.322429</td>\n",
       "      <td>-0.335741</td>\n",
       "      <td>-0.39144</td>\n",
       "      <td>-0.424744</td>\n",
       "      <td>-0.442341</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.265351</td>\n",
       "      <td>-0.264938</td>\n",
       "      <td>-0.332012</td>\n",
       "      <td>-0.323045</td>\n",
       "      <td>-0.285949</td>\n",
       "      <td>-0.280206</td>\n",
       "      <td>-0.310537</td>\n",
       "      <td>-0.255797</td>\n",
       "      <td>-0.310412</td>\n",
       "      <td>-0.290698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Floor 1</td>\n",
       "      <td>216441698810</td>\n",
       "      <td>ad24cd</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.391508</td>\n",
       "      <td>-0.322429</td>\n",
       "      <td>-0.335741</td>\n",
       "      <td>-0.39144</td>\n",
       "      <td>-0.424744</td>\n",
       "      <td>-0.442341</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.265351</td>\n",
       "      <td>-0.264938</td>\n",
       "      <td>-0.332012</td>\n",
       "      <td>-0.323045</td>\n",
       "      <td>-0.285949</td>\n",
       "      <td>-0.280206</td>\n",
       "      <td>-0.310537</td>\n",
       "      <td>-0.255797</td>\n",
       "      <td>-0.310412</td>\n",
       "      <td>-0.290698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Floor 1</td>\n",
       "      <td>216441698810</td>\n",
       "      <td>ad24cd</td>\n",
       "      <td>21</td>\n",
       "      <td>-0.391508</td>\n",
       "      <td>-0.322429</td>\n",
       "      <td>-0.335741</td>\n",
       "      <td>-0.39144</td>\n",
       "      <td>-0.424744</td>\n",
       "      <td>-0.442341</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.265351</td>\n",
       "      <td>-0.264938</td>\n",
       "      <td>-0.332012</td>\n",
       "      <td>-0.323045</td>\n",
       "      <td>-0.285949</td>\n",
       "      <td>-0.280206</td>\n",
       "      <td>-0.310537</td>\n",
       "      <td>-0.255797</td>\n",
       "      <td>-0.310412</td>\n",
       "      <td>-0.290698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1855 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      zone    session_id  tag_id  Unnamed: 3         0         1         2  \\\n",
       "0  Floor 1  216441698810  ad24cd          17 -0.391508 -0.322429 -0.335741   \n",
       "1  Floor 1  216441698810  ad24cd          18 -0.391508 -0.322429 -0.335741   \n",
       "2  Floor 1  216441698810  ad24cd          19 -0.391508 -0.322429 -0.335741   \n",
       "3  Floor 1  216441698810  ad24cd          20 -0.391508 -0.322429 -0.335741   \n",
       "4  Floor 1  216441698810  ad24cd          21 -0.391508 -0.322429 -0.335741   \n",
       "\n",
       "         3         4         5  ...      1841      1842      1843      1844  \\\n",
       "0 -0.39144 -0.424744 -0.442341  ... -0.265351 -0.264938 -0.332012 -0.323045   \n",
       "1 -0.39144 -0.424744 -0.442341  ... -0.265351 -0.264938 -0.332012 -0.323045   \n",
       "2 -0.39144 -0.424744 -0.442341  ... -0.265351 -0.264938 -0.332012 -0.323045   \n",
       "3 -0.39144 -0.424744 -0.442341  ... -0.265351 -0.264938 -0.332012 -0.323045   \n",
       "4 -0.39144 -0.424744 -0.442341  ... -0.265351 -0.264938 -0.332012 -0.323045   \n",
       "\n",
       "       1845      1846      1847      1848      1849      1850  \n",
       "0 -0.285949 -0.280206 -0.310537 -0.255797 -0.310412 -0.290698  \n",
       "1 -0.285949 -0.280206 -0.310537 -0.255797 -0.310412 -0.290698  \n",
       "2 -0.285949 -0.280206 -0.310537 -0.255797 -0.310412 -0.290698  \n",
       "3 -0.285949 -0.280206 -0.310537 -0.255797 -0.310412 -0.290698  \n",
       "4 -0.285949 -0.280206 -0.310537 -0.255797 -0.310412 -0.290698  \n",
       "\n",
       "[5 rows x 1855 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df = pd.read_csv('saved_val_df_idx.csv')\n",
    "print(f\"Shape of the validation matrix: {val_df.shape}\")\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression()\n",
    "svc = SVC()\n",
    "dt = DecisionTreeClassifier(criterion='gini')\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "ada = AdaBoostClassifier(n_estimators=50, learning_rate=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sw_rtls_algo_util.preprocessing.pipes import (\n",
    "    cleaned_df_to_lstm_data\n",
    ")\n",
    "\n",
    "from sw_rtls_algo_util.preprocessing.transforms import (\n",
    "    generate_lstm_data,\n",
    "    generate_lookback,\n",
    "    lookback_numpy\n",
    ")\n",
    "\n",
    "from sw_rtls_algo_util.encoder_io import load_encoder\n",
    "\n",
    "sensor_encoder = load_encoder('model/sensor_encoder.pkl')\n",
    "zone_encoder = load_encoder('model/zone_encoder.pkl')\n",
    "rssi_standardizer = load_encoder('model/rssi_standardizer.pkl')\n",
    "\n",
    "train_data, train_labels = generate_lstm_data(train_df, zone_encoder, lookback=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = generate_lookback(val_df, 1, inference_version=False)\n",
    "zone = data.reset_index()['zone']\n",
    "tag = data.reset_index()['tag_id']\n",
    "labels = []\n",
    "for zone, feature, tag in zip(zone,data.values, tag):\n",
    "    labels = labels+[zone]*len(feature)\n",
    "\n",
    "features = data.values\n",
    "for i in range(len(features)):\n",
    "    if len(features[i].shape) < 2:\n",
    "        features[i] = features[i].reshape(1, -1)\n",
    "val_data = np.concatenate(features)\n",
    "\n",
    "converted_zone = np.array(labels).reshape(-1,1)\n",
    "enc_y = zone_encoder.transform(converted_zone)\n",
    "val_labels = enc_y.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels = val_labels[:290184]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[:,4:]\n",
    "val_data = val_data[:,4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Train a model and report its performance\n",
    "def train_and_eval(model, name, features, labels, test_features, test_labels):\n",
    "    # Transform the labels into a 1d array\n",
    "    if name in ['logit', 'svc', 'ada', 'xgb']:\n",
    "        labels = np.argmax(labels, 1)\n",
    "        test_labels = np.argmax(test_labels, 1)\n",
    "\n",
    "    if name == 'xgb':\n",
    "        dtrain = xgb.DMatrix(features[:int(0.8*features.shape[0])], labels[:int(0.8*features.shape[0])])\n",
    "        param = {\n",
    "            'max_depth': 10,\n",
    "            'eta': 0.5,\n",
    "            'objective': 'multi:softmax',\n",
    "            'num_class': 4\n",
    "            }\n",
    "        dtest = xgb.DMatrix(features[int(0.8*features.shape[0]):], labels[int(0.8*features.shape[0]):])\n",
    "        evallist = [(dtest, 'eval'), (dtrain, 'train')]\n",
    "        num_round = 30\n",
    "        start = time.perf_counter()\n",
    "        bst = xgb.train(param, dtrain, num_round, evallist)\n",
    "        fit_time = time.perf_counter()-start\n",
    "        dval = xgb.DMatrix(test_features)\n",
    "\n",
    "        start = time.perf_counter()\n",
    "        preds = bst.predict(dval)\n",
    "        inf_time = time.perf_counter()-start\n",
    "        acc = sum(preds == test_labels)\n",
    "\n",
    "        bst.save_model('xgb_multifloor.model')\n",
    "        \n",
    "        print(\"Accuracy: \", acc/test_labels.shape[0])\n",
    "        return {\n",
    "            \"Score\": acc/test_labels.shape[0],\n",
    "            \"Fit time\": fit_time,\n",
    "            \"Predict time\": inf_time,\n",
    "            \"Name\": name\n",
    "        }\n",
    "\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    model.fit(features, labels)\n",
    "    print(\"The model is fit\")\n",
    "    fit_time = time.perf_counter()-start\n",
    "    print(f\"Fit time is {fit_time}\")\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    score = model.score(test_features, test_labels)\n",
    "    inf_time = time.perf_counter() - start\n",
    "    print(f\"Time to predict the score: {inf_time}\")\n",
    "    print(f\"Model {model.__name__} has score: {score}\")\n",
    "    return {\n",
    "        \"Score\": score,\n",
    "        \"Fit time\": fit_time,\n",
    "        \"Predict time\": inf_time,\n",
    "        \"Name\": name\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate proportional but trimmed datasets\n",
    "\n",
    "value_counts = train_df['zone'].value_counts()\n",
    "v1 = value_counts['Floor 1']\n",
    "v2 = value_counts['Floor 2']\n",
    "v3 = value_counts['Floor 3']\n",
    "v4 = value_counts['Floor 4']\n",
    "\n",
    "# Extract a subset of training data that is proportional to what existed\n",
    "f1_prop = v1/train_df.shape[0]\n",
    "f2_prop = v2/train_df.shape[0]\n",
    "f3_prop = v3/train_df.shape[0]\n",
    "f4_prop = v4/train_df.shape[0]\n",
    "\n",
    "sample_total = 80000 # There wiill be 80000 rows in final training data\n",
    "trimmed_train_data = train_data[0:int(math.floor(f1_prop*sample_total))]\n",
    "trimmed_train_data = np.vstack((trimmed_train_data, train_data[v1:v1+int(math.floor(f2_prop*sample_total))]))\n",
    "trimmed_train_data = np.vstack((trimmed_train_data, train_data[v1+v2:v1+v2+int(math.floor(f3_prop*sample_total))]))\n",
    "trimmed_train_data = np.vstack((trimmed_train_data, train_data[v1+v2+v3:v1+v2+v3+int(math.floor(f4_prop*sample_total))]))\n",
    "\n",
    "trimmed_train_labels = train_labels[0:int(math.floor(f1_prop*sample_total))]\n",
    "trimmed_train_labels = np.vstack((trimmed_train_labels, train_labels[v1:v1+int(math.floor(f2_prop*sample_total))]))\n",
    "trimmed_train_labels = np.vstack((trimmed_train_labels, train_labels[v1+v2:v1+v2+int(math.floor(f3_prop*sample_total))]))\n",
    "trimmed_train_labels = np.vstack((trimmed_train_labels, train_labels[v1+v2+v3:v1+v2+v3+int(math.floor(f4_prop*sample_total))]))\n",
    "\n",
    "np.save('trimmed_train_features', trimmed_train_data, allow_pickle=True)\n",
    "np.save('trimmed_train_labels', trimmed_train_labels, allow_pickle=True)\n",
    "\n",
    "value_counts = val_df['zone'].value_counts()\n",
    "v1 = value_counts['Floor 1']\n",
    "v2 = value_counts['Floor 2']\n",
    "v3 = value_counts['Floor 3']\n",
    "v4 = value_counts['Floor 4']\n",
    "\n",
    "# Extract a subset of training data that is proportional to what existed\n",
    "f1_prop = v1/val_df.shape[0]\n",
    "f2_prop = v2/val_df.shape[0]\n",
    "f3_prop = v3/val_df.shape[0]\n",
    "f4_prop = v4/val_df.shape[0]\n",
    "\n",
    "sample_total = 20000 # There wiill be 80000 rows in final training data\n",
    "trimmed_val_data = val_data[0:int(math.floor(f1_prop*sample_total))]\n",
    "trimmed_val_data = np.vstack((trimmed_val_data, val_data[v1:v1+int(math.floor(f2_prop*sample_total))]))\n",
    "trimmed_val_data = np.vstack((trimmed_val_data, val_data[v1+v2:v1+v2+int(math.floor(f3_prop*sample_total))]))\n",
    "trimmed_val_data = np.vstack((trimmed_val_data, val_data[v1+v2+v3:v1+v2+v3+int(math.floor(f4_prop*sample_total))]))\n",
    "\n",
    "trimmed_val_labels = val_labels[0:int(math.floor(f1_prop*sample_total))]\n",
    "trimmed_val_labels = np.vstack((trimmed_val_labels, val_labels[v1:v1+int(math.floor(f2_prop*sample_total))]))\n",
    "trimmed_val_labels = np.vstack((trimmed_val_labels, val_labels[v1+v2:v1+v2+int(math.floor(f3_prop*sample_total))]))\n",
    "trimmed_val_labels = np.vstack((trimmed_val_labels, val_labels[v1+v2+v3:v1+v2+v3+int(math.floor(f4_prop*sample_total))]))\n",
    "\n",
    "np.save('trimmed_val_features', trimmed_val_data, allow_pickle=True)\n",
    "np.save('trimmed_val_labels', trimmed_val_labels, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(297519, 3702)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.reshape((-1,2*1851)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24182, 4)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[::12].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lookback_numpy(train_data, 3, 1851)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_labels[2:]\n",
    "val_data = lookback_numpy(val_data, 3, 1851)\n",
    "val_labels = val_labels[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(595036, 5553)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.reshape((-1, train_data.shape[1]*train_data.shape[2])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores = []\n",
    "# scores.append(train_and_eval(rf, \"rf\", trimmed_train_data, trimmed_train_labels, trimmed_val_data, trimmed_val_labels))\n",
    "# scores.append(train_and_eval(rf, 'rf', train_data, train_labels, val_data, val_labels))\n",
    "scores.append(train_and_eval(rf, 'rf', train_data.reshape((-1, train_data.shape[1]*train_data.shape[2])), train_labels, val_data.reshape((-1, val_data.shape[1]*val_data.shape[2])), val_labels))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iradovic/Library/Caches/pypoetry/virtualenvs/sw-rtls-ml-service-gBjmajZM-py3.9/lib/python3.9/site-packages/xgboost/core.py:525: FutureWarning: Pass `evals` as keyword args.  Passing these as positional arguments will be considered as error in future releases.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-mlogloss:1.53741\ttrain-mlogloss:0.63646\n",
      "[1]\teval-mlogloss:1.74025\ttrain-mlogloss:0.36879\n",
      "[2]\teval-mlogloss:2.05382\ttrain-mlogloss:0.22679\n",
      "[3]\teval-mlogloss:2.32502\ttrain-mlogloss:0.14334\n",
      "[4]\teval-mlogloss:2.59674\ttrain-mlogloss:0.09534\n",
      "[5]\teval-mlogloss:2.92757\ttrain-mlogloss:0.06451\n",
      "[6]\teval-mlogloss:3.23519\ttrain-mlogloss:0.04477\n",
      "[7]\teval-mlogloss:3.49323\ttrain-mlogloss:0.03049\n",
      "[8]\teval-mlogloss:3.81132\ttrain-mlogloss:0.02065\n",
      "[9]\teval-mlogloss:4.08903\ttrain-mlogloss:0.01402\n",
      "[10]\teval-mlogloss:4.36876\ttrain-mlogloss:0.00991\n",
      "[11]\teval-mlogloss:4.62688\ttrain-mlogloss:0.00713\n",
      "[12]\teval-mlogloss:4.85881\ttrain-mlogloss:0.00524\n",
      "[13]\teval-mlogloss:5.12761\ttrain-mlogloss:0.00397\n",
      "[14]\teval-mlogloss:5.39171\ttrain-mlogloss:0.00296\n",
      "[15]\teval-mlogloss:5.61442\ttrain-mlogloss:0.00234\n",
      "[16]\teval-mlogloss:5.89261\ttrain-mlogloss:0.00177\n",
      "[17]\teval-mlogloss:6.16174\ttrain-mlogloss:0.00140\n",
      "[18]\teval-mlogloss:6.42658\ttrain-mlogloss:0.00112\n",
      "[19]\teval-mlogloss:6.70526\ttrain-mlogloss:0.00090\n",
      "[20]\teval-mlogloss:6.97266\ttrain-mlogloss:0.00071\n",
      "[21]\teval-mlogloss:7.23806\ttrain-mlogloss:0.00057\n",
      "[22]\teval-mlogloss:7.47826\ttrain-mlogloss:0.00047\n",
      "[23]\teval-mlogloss:7.74214\ttrain-mlogloss:0.00039\n",
      "[24]\teval-mlogloss:7.98868\ttrain-mlogloss:0.00033\n",
      "[25]\teval-mlogloss:8.23178\ttrain-mlogloss:0.00028\n",
      "[26]\teval-mlogloss:8.43041\ttrain-mlogloss:0.00023\n",
      "[27]\teval-mlogloss:8.61141\ttrain-mlogloss:0.00019\n",
      "[28]\teval-mlogloss:8.80145\ttrain-mlogloss:0.00016\n",
      "[29]\teval-mlogloss:8.99793\ttrain-mlogloss:0.00014\n",
      "Accuracy:  0.8426756816364789\n"
     ]
    }
   ],
   "source": [
    "scores.append(train_and_eval(None, 'xgb', train_data, train_labels, val_data, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is fit\n",
      "Fit time is 290.44706937499905\n",
      "Time to predict the score: 22.539450459000363\n"
     ]
    }
   ],
   "source": [
    "# scores.append(train_and_eval(dt, \"dt\", trimmed_train_data, trimmed_train_labels, trimmed_val_data, trimmed_val_labels))\n",
    "scores.append(train_and_eval(dt, 'dt', train_data, train_labels, val_data, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is fit\n",
      "Fit time is 3781.4371871669996\n",
      "Time to predict the score: 943.61152425\n"
     ]
    }
   ],
   "source": [
    "# scores.append(train_and_eval(ada, \"ada\", trimmed_train_data, trimmed_train_labels, trimmed_val_data, trimmed_val_labels))\n",
    "scores.append(train_and_eval(ada, 'ada', train_data, train_labels, val_data, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iradovic/Library/Caches/pypoetry/virtualenvs/sw-rtls-ml-service-gBjmajZM-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is fit\n",
      "Fit time is 216.215461\n",
      "Time to predict the score: 29.07787237499997\n"
     ]
    }
   ],
   "source": [
    "# scores.append(train_and_eval(logit, \"logit\", trimmed_train_data, trimmed_train_labels, trimmed_val_data, trimmed_val_labels))\n",
    "scores.append(train_and_eval(logit, 'logit', train_data, train_labels, val_data, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is fit\n",
      "Fit time is 8571.964375042\n",
      "Time to predict the score: 3026.7402966669997\n"
     ]
    }
   ],
   "source": [
    "# scores.append(train_and_eval(svc, \"svc\", trimmed_train_data, trimmed_train_labels, trimmed_val_data, trimmed_val_labels))\n",
    "scores.append(train_and_eval(svc, 'svc', train_data, train_labels, val_data, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Score': 0.8426756816364789, 'Fit time': 550.6219452500009, 'Predict time': 0.19181791700066242, 'Name': 'xgb'}, {'Score': 0.9480605408981887, 'Fit time': 290.44706937499905, 'Predict time': 22.539450459000363, 'Name': 'dt'}]\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_ml_model(model, filename):\n",
    "    import pickle\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "    \n",
    "def load_ml_model(filename):\n",
    "    import pickle\n",
    "    return pickle.load(open(filename, 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_ml_model(dt, 'dt_multifloor.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------- Keras Model ---------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "train_features = lookback_numpy(train_data, lookback=20, num_sensors=train_data.shape[1])\n",
    "val_features = lookback_numpy(val_data, lookback=20, num_sensors=val_data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(595019, 4)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_lstm = train_labels[19:]\n",
    "train_labels_lstm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 32.00 GB\n",
      "maxCacheSize: 10.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-27 11:25:34.437138: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-07-27 11:25:34.437852: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dropout(0.25, input_shape=(train_features.shape[1], train_features.shape[2])))\n",
    "model.add(keras.layers.LSTM(200))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Dense(train_labels_lstm.shape[1]))\n",
    "\n",
    "learning_rate_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=5e-4,\n",
    "        decay_steps=15000,\n",
    "        decay_rate=0.95\n",
    "    )\n",
    "optimizer = keras.optimizers.Adam(learning_rate=learning_rate_schedule)\n",
    "\n",
    "model.compile(optimizer, loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "train_features = np.asarray(train_features).astype('float32')\n",
    "train_labels = np.asarray(train_labels).astype('float32')\n",
    "model.fit(train_features, train_labels_lstm, batch_size=64, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/iradovic/VSCodeProjects/sw_rtls_ml_service/alternatives.ipynb Cell 25'\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/iradovic/VSCodeProjects/sw_rtls_ml_service/alternatives.ipynb#ch0000048?line=8'>9</a>\u001b[0m rf2 \u001b[39m=\u001b[39m RandomForestClassifier()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/iradovic/VSCodeProjects/sw_rtls_ml_service/alternatives.ipynb#ch0000048?line=9'>10</a>\u001b[0m clf \u001b[39m=\u001b[39m GridSearchCV(rf2, rf_parameters)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/iradovic/VSCodeProjects/sw_rtls_ml_service/alternatives.ipynb#ch0000048?line=10'>11</a>\u001b[0m clf\u001b[39m.\u001b[39;49mfit(train_data, train_labels)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/sw-rtls-ml-service-gBjmajZM-py3.9/lib/python3.9/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    869\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    871\u001b[0m     )\n\u001b[1;32m    873\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 875\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    877\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    879\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/sw-rtls-ml-service-gBjmajZM-py3.9/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1375\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1374\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1375\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/sw-rtls-ml-service-gBjmajZM-py3.9/lib/python3.9/site-packages/sklearn/model_selection/_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    815\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    817\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    819\u001b[0m         )\n\u001b[1;32m    820\u001b[0m     )\n\u001b[0;32m--> 822\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    823\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    824\u001b[0m         clone(base_estimator),\n\u001b[1;32m    825\u001b[0m         X,\n\u001b[1;32m    826\u001b[0m         y,\n\u001b[1;32m    827\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    828\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    829\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    830\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    831\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    832\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    833\u001b[0m     )\n\u001b[1;32m    834\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    835\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    836\u001b[0m     )\n\u001b[1;32m    837\u001b[0m )\n\u001b[1;32m    839\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    840\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    844\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/sw-rtls-ml-service-gBjmajZM-py3.9/lib/python3.9/site-packages/joblib/parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1044\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1046\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1047\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1050\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/sw-rtls-ml-service-gBjmajZM-py3.9/lib/python3.9/site-packages/joblib/parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 861\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/sw-rtls-ml-service-gBjmajZM-py3.9/lib/python3.9/site-packages/joblib/parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    778\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 779\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    780\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/sw-rtls-ml-service-gBjmajZM-py3.9/lib/python3.9/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/sw-rtls-ml-service-gBjmajZM-py3.9/lib/python3.9/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/sw-rtls-ml-service-gBjmajZM-py3.9/lib/python3.9/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/sw-rtls-ml-service-gBjmajZM-py3.9/lib/python3.9/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/sw-rtls-ml-service-gBjmajZM-py3.9/lib/python3.9/site-packages/sklearn/utils/fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[0;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "rf_parameters = {\n",
    "    \"n_estimators\": [50, 100, 150],\n",
    "    \"criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "    \"max_depth\": [None, 3, 5],\n",
    "    \"max_features\": [\"sqrt\", \"log2\", None],\n",
    "    \"n_jobs\": [-1]\n",
    "}\n",
    "rf2 = RandomForestClassifier()\n",
    "clf = GridSearchCV(rf2, rf_parameters)\n",
    "clf.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_parameters = {\n",
    "    \"penalty\": ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    \"tol\": [1e-3, 1e-4, 1e-5],\n",
    "    \"C\": [0.1, 1.0, 10],\n",
    "    \"class_weight\": [None, 'balanced'],\n",
    "    \"max_iter\": [50, 100, 150],\n",
    "    \"n_jobs\": [-1]\n",
    "}\n",
    "lr = LogisticRegression()\n",
    "lr_grid_search = GridSearchCV(lr, lr_parameters)\n",
    "lr_grid_search.fit(train_data, train_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('sw-rtls-ml-service-r7LqsROn-py3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c283f959709b8423043dc1d303113c96374b51505efbb226d289176c3bcd5384"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
